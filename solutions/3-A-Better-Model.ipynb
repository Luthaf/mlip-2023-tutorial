{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving the model with a LJ baseline\n",
    "\n",
    "In the previous notebook, we saw that our initial model was not very stable. One\n",
    "possible improvement would be to add a Lennard-Jones potential as a baseline,\n",
    "ensuring the model is repulsive at short distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Optional\n",
    "import math\n",
    "\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(123456)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ase.io\n",
    "\n",
    "from metatensor.torch import TensorBlock, Labels\n",
    "from metatensor.torch.atomistic import System as MetatensorSystem\n",
    "from metatensor.torch.atomistic import NeighborsListOptions\n",
    "from metatensor.torch.atomistic import ModelCapabilities, ModelOutput, ModelRunOptions\n",
    "from metatensor.torch.atomistic import MetatensorAtomisticModule\n",
    "from metatensor.torch.atomistic.ase_calculator import MetatensorCalculator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a Lennard-Jones energy module\n",
    "\n",
    "The Lennard-Jones potential is a classical potential with the following functional form:\n",
    "\n",
    "$$\n",
    "E = \\sum_{ij} 4 \\varepsilon \\left[\\left(\\frac{\\sigma}{r_{ij}}\\right)^{12} - \\left(\\frac{\\sigma}{r_{ij}}\\right)^6\\right]\n",
    "$$\n",
    "\n",
    "Where the sum runs over all pairs in the system with a distance below the cutoff radius $r_c$.\n",
    "\n",
    "Using the formula above directly however comes with discontinuity issues: as the\n",
    "atoms enter and leave the cutoff, there is a jump and discontinuity in energies.\n",
    "One solution is to shift the energy to 0 at the cutoff, leaving only a small\n",
    "discontinuity in the forces.\n",
    "\n",
    "$$\n",
    "E = \\sum_{ij} 4 \\varepsilon \\left[\\left(\\frac{\\sigma}{r_{ij}}\\right)^{12} - \\left(\\frac{\\sigma}{r_{ij}}\\right)^6\\right] - 4 \\varepsilon \\left[\\left(\\frac{\\sigma}{r_c}\\right)^{12} - \\left(\\frac{\\sigma}{r_c}\\right)^6\\right]\n",
    "$$\n",
    "\n",
    "To be able to compute the Lennard-Jones energy of a system, we need a list of\n",
    "all pairs below the cutoff. Ideally, we will want to get such list of pairs\n",
    "directly from the MD engine, which can use some trick for a faster\n",
    "re-calculation of the list. For a metatensor atomistic model, this can be\n",
    "achieved by requesting some neighbors lists with a `requested_neighbors_lists()`\n",
    "function, and then accessing these neighbors lists in the `forward()` function.\n",
    "\n",
    "\n",
    "| ![TASK](../images/clipboard.png) | Modify the loop over pairs in `forward()` to compute the LJ energy |\n",
    "|-------------------------------|--------------------------------------------------------------------|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LennardJones(torch.nn.Module):\n",
    "    def __init__(self, cutoff, parameters: Dict[int, Dict[str, float]]):\n",
    "        super().__init__()\n",
    "        self.cutoff = float(cutoff)\n",
    "\n",
    "        # The neighbors list request we are making:\n",
    "        self._neighbors = NeighborsListOptions(cutoff=self.cutoff, full_list=False)\n",
    "\n",
    "        self._lj_params = {}\n",
    "        for s_i, p_i in parameters.items():\n",
    "            sigma_i = p_i[\"sigma\"]\n",
    "            epsilon_i = p_i[\"epsilon\"]\n",
    "            self._lj_params[s_i] = {}\n",
    "\n",
    "            for s_j, p_j in parameters.items():\n",
    "                sigma_j = p_j[\"sigma\"]\n",
    "                epsilon_j = p_j[\"epsilon\"]\n",
    "\n",
    "                # combine parameters with Lorentz-Berthelot rules\n",
    "                sigma = (sigma_i + sigma_j) / 2\n",
    "                epsilon = math.sqrt(epsilon_i * epsilon_j)\n",
    "\n",
    "                # compute the energy at the cutoff for these parameters, to remove it\n",
    "                # from the energy of a pair in forward\n",
    "                energy_at_cutoff = (\n",
    "                    4 * epsilon * ((sigma / cutoff) ** 12 - (sigma / cutoff) ** 6)\n",
    "                )\n",
    "\n",
    "                self._lj_params[s_i][s_j] = [sigma, epsilon, energy_at_cutoff]\n",
    "\n",
    "    # exposed the requested neighbors list so metatensor can find it\n",
    "    def requested_neighbors_lists(self) -> List[NeighborsListOptions]:\n",
    "        return [self._neighbors]\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        system: MetatensorSystem,\n",
    "        run_options: ModelRunOptions,\n",
    "    ) -> Dict[str, TensorBlock]:\n",
    "        if \"energy\" not in run_options.outputs:\n",
    "            return {}\n",
    "\n",
    "        # The neighbors list was computed by the MD engine and\n",
    "        # is available as a TensorBlock\n",
    "        neighbors = system.get_neighbors_list(self._neighbors)\n",
    "        # the samples of this block are\n",
    "        #     first_atom   second_atom   cell_shift_a   cell_shift_b   cell_shift_c\n",
    "        all_i = neighbors.samples.column(\"first_atom\")\n",
    "        all_j = neighbors.samples.column(\"second_atom\")\n",
    "        all_S = neighbors.samples.view(\n",
    "            [\"cell_shift_a\", \"cell_shift_b\", \"cell_shift_c\"]\n",
    "        ).values\n",
    "\n",
    "        # The system contains data about the positions and cell, also as TensorBlock\n",
    "        cell = system.cell.values.reshape(3, 3)\n",
    "        positions = system.positions.values.reshape(-1, 3)\n",
    "\n",
    "        # system.positions samples are \"atom\" and \"species\", we need the species here\n",
    "        # to access the right LJ parameters\n",
    "        species = system.positions.samples.column(\"species\")\n",
    "\n",
    "        selected_atoms = run_options.selected_atoms\n",
    "        if selected_atoms is None:\n",
    "            selected_atoms = [i for i in range(positions.shape[0])]\n",
    "\n",
    "        total_energy = torch.zeros(1, dtype=positions.dtype)\n",
    "        # loop over all pairs\n",
    "        for i, j, S in zip(all_i, all_j, all_S):\n",
    "            # get the parameters for the current pair of species\n",
    "            sigma, epsilon, shift = self._lj_params[int(species[i])][int(species[j])]\n",
    "            # compute the distance between the two atoms\n",
    "            distance = positions[j] - positions[i] + S.to(dtype=cell.dtype) @ cell\n",
    "\n",
    "            # square of the distance between the atoms\n",
    "            r2 = distance.dot(distance)\n",
    "\n",
    "            r = r2.sqrt()\n",
    "            e_ij = 4 * epsilon * ((sigma / r) ** 12 - (sigma / r) ** 6)\n",
    "\n",
    "            total_energy += e_ij - shift\n",
    "\n",
    "        # as previously, return a Dict of TensorBlock containing the energy\n",
    "        return {\n",
    "            \"energy\": TensorBlock(\n",
    "                values=total_energy.reshape(1, 1),\n",
    "                samples=Labels([\"_\"], torch.IntTensor([[0]])),\n",
    "                components=[],\n",
    "                properties=Labels([\"energy\"], torch.IntTensor([[0]])),\n",
    "            )\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# energies in eV and distances in Angstroms\n",
    "LJ_PARAMETERS = {\n",
    "    1: {\"sigma\": 2.32, \"epsilon\": 3.3104e-6},\n",
    "    6: {\"sigma\": 2.94, \"epsilon\": 2.3309e-6},\n",
    "    8: {\"sigma\": 2.66, \"epsilon\": 2.4673e-6},\n",
    "}\n",
    "\n",
    "lj = LennardJones(cutoff=6.0, parameters=LJ_PARAMETERS)\n",
    "lj = lj.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "frames = ase.io.read(\"ethanol_conformers_dftb.xyz\", \":500\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a custom Lennard-Jones implementation, we can use the same \n",
    "facilities to export it as a `MetatensorAtomisticModule` and use it in \n",
    "ASE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capabilities = ModelCapabilities(\n",
    "    length_unit=\"angstrom\",\n",
    "    species=[1, 6, 8],\n",
    "    outputs={\n",
    "        \"energy\": ModelOutput(\n",
    "            quantity=\"energy\",\n",
    "            unit=\"eV\",\n",
    "            per_atom=False,\n",
    "        ),\n",
    "    },\n",
    ")\n",
    "\n",
    "# when using `MetatensorCalculator`, the neighbors lists are provided by ASE.\n",
    "#\n",
    "# notice that we don't need to export the model to a file to be able to use it with ASE.\n",
    "ase_calculator = MetatensorCalculator(MetatensorAtomisticModule(lj, capabilities))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by checking that the code runs and produces a reasonable output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the code runs fine on the first frame\n",
    "atoms = frames[0]\n",
    "atoms.calc = ase_calculator\n",
    "\n",
    "energy = atoms.get_potential_energy()\n",
    "if abs(energy - 3.05) > 0.1:\n",
    "    raise Exception(f\"the energy seems wrong: {energy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can modify our training set to remove the part accounted for by the LJ module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energies = []\n",
    "forces = []\n",
    "\n",
    "# remove the LJ energies and forces from the targets\n",
    "for atoms in frames:\n",
    "    atoms.calc = ase_calculator\n",
    "    energies.append(atoms.info[\"energy\"] - atoms.get_potential_energy())\n",
    "    forces.append(atoms.arrays[\"forces\"] - atoms.get_forces())\n",
    "\n",
    "energies = np.vstack(energies)\n",
    "forces = np.vstack(forces)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the NN, again!\n",
    "\n",
    "Let's load back our model, and re-train it on the new targets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rascaline.torch\n",
    "from rascaline.torch import (\n",
    "    SoapPowerSpectrum,\n",
    "    systems_to_torch,\n",
    "    metatensor_system_to_rascaline,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the same definition as in notebook 1\n",
    "\n",
    "class EthanolModel(torch.nn.Module):\n",
    "    def __init__(self, soap_parameters, species, energy_offset):\n",
    "        super().__init__()\n",
    "\n",
    "        self.energy_offset = torch.tensor(energy_offset)\n",
    "        self.species = species\n",
    "\n",
    "        self.soap_calculator = SoapPowerSpectrum(**soap_parameters)\n",
    "        self.species_pairs = torch.IntTensor(\n",
    "            [(i, j) for i in species for j in species if i <= j]\n",
    "        )\n",
    "\n",
    "        # Number of features produced by the SOAP calculator,\n",
    "        # i.e. size of the input of the NN\n",
    "        n_soap = (\n",
    "            (soap_parameters[\"max_angular\"] + 1)\n",
    "            * soap_parameters[\"max_radial\"] ** 2\n",
    "            * len(self.species_pairs)\n",
    "        )\n",
    "\n",
    "        # Definition of our NN: one hidden layer,\n",
    "        # SiLU activation, 128-sized latent space\n",
    "        self.soap_nn = torch.nn.Sequential(\n",
    "            torch.nn.Linear(\n",
    "                in_features=n_soap, out_features=128, bias=False, dtype=torch.float64\n",
    "            ),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(\n",
    "                in_features=128, out_features=128, bias=False, dtype=torch.float64\n",
    "            ),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(\n",
    "                in_features=128, out_features=1, bias=True, dtype=torch.float64\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        systems: List[rascaline.torch.System],\n",
    "        selected_samples: Optional[Labels] = None,\n",
    "    ):\n",
    "        energies = torch.zeros((len(systems), 1), dtype=torch.float64)\n",
    "        for i, system in enumerate(systems):\n",
    "            soap = self.soap_calculator([system], selected_samples=selected_samples)\n",
    "            soap = soap.keys_to_properties(\n",
    "                Labels([\"species_neighbor_1\", \"species_neighbor_2\"], self.species_pairs)\n",
    "            )\n",
    "            soap = soap.keys_to_samples(\"species_center\")\n",
    "\n",
    "            energies_per_atom = self.soap_nn(soap.block().values)\n",
    "            energies[i] = energies_per_atom.sum()\n",
    "\n",
    "        return energies + self.energy_offset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOAP_PARAMETERS = {\n",
    "    \"cutoff\": 3.5,\n",
    "    \"max_radial\": 6,\n",
    "    \"max_angular\": 6,\n",
    "    \"atomic_gaussian_width\": 0.3,\n",
    "    \"center_atom_weight\": 1.0,\n",
    "    \"radial_basis\": {\"Gto\": {}},\n",
    "    \"cutoff_function\": {\"ShiftedCosine\": {\"width\": 0.5}},\n",
    "}\n",
    "\n",
    "model = EthanolModel(\n",
    "    SOAP_PARAMETERS,\n",
    "    species=[1, 6, 8],\n",
    "    energy_offset= energies.mean(),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.005)\n",
    "epoch = -1\n",
    "\n",
    "systems = systems_to_torch(frames)\n",
    "reference = torch.tensor(energies)\n",
    "\n",
    "mse_loss = torch.nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training procedure will be very similar to the previous one.\n",
    "\n",
    "| ![TASK](../images/clipboard.png) | Run the training loop until the loss is below 0.05 |\n",
    "|-------------------------------|----------------------------------------------------|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = epoch + 1\n",
    "\n",
    "for epoch in range(start, start + 75):\n",
    "    optimizer.zero_grad()\n",
    "    prediction = model(systems)\n",
    "    loss = mse_loss(prediction, reference)\n",
    "    print(f\"loss at epoch {epoch} is\", loss.item())\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if loss.item() > 0.05:\n",
    "    raise Exception(\n",
    "        f\"loss is still too high, please continue running the training loop\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the output against the reference (without the LJ contributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_energy = model(systems)\n",
    "\n",
    "plt.scatter(energies, predicted_energy.detach().numpy())\n",
    "\n",
    "x = [np.min(energies), np.max(energies)]\n",
    "plt.plot(x, x, c=\"grey\")\n",
    "\n",
    "plt.title(\"energies\")\n",
    "plt.xlabel(\"reference\")\n",
    "plt.ylabel(\"predicted\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-assemble the full model\n",
    "\n",
    "We can now assemble a new model using both the LJ contributions and the\n",
    "re-trained SOAP neural network. We'll run both here, and add their outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExportWrapper(torch.nn.Module):\n",
    "    def __init__(self, lj, nn_model):\n",
    "        super().__init__()\n",
    "        self.lj = lj\n",
    "        self.nn_model = nn_model\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        system: MetatensorSystem,\n",
    "        run_options: ModelRunOptions,\n",
    "    ) -> Dict[str, TensorBlock]:\n",
    "        if \"energy\" not in run_options.outputs:\n",
    "            return {}\n",
    "\n",
    "        # run the LJ model\n",
    "        outputs = self.lj(system, run_options)\n",
    "        lj_energy = outputs[\"energy\"]\n",
    "\n",
    "        # run the NN model\n",
    "        selected_atoms = run_options.selected_atoms\n",
    "        if selected_atoms is None:\n",
    "            selected_samples = None\n",
    "        else:\n",
    "            selected_samples = Labels(\n",
    "                \"center\", torch.IntTensor(selected_atoms).reshape(-1, 1)\n",
    "            )\n",
    "\n",
    "        nn_energy = self.nn_model(\n",
    "            metatensor_system_to_rascaline(system),\n",
    "            selected_samples=selected_samples,\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"energy\": TensorBlock(\n",
    "                values=lj_energy.values + nn_energy.reshape(1, 1),\n",
    "                samples=Labels(\"_\", torch.IntTensor([[0]])),\n",
    "                components=[],\n",
    "                properties=Labels(\"energy\", torch.IntTensor([[0]])),\n",
    "            )\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this done, we can define the capabilities of our new model, and export it to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper = ExportWrapper(lj, model)\n",
    "wrapper = wrapper.eval()\n",
    "\n",
    "capabilities = ModelCapabilities(\n",
    "    length_unit=\"angstrom\",\n",
    "    species=[1, 6, 8],\n",
    "    outputs={\n",
    "        \"energy\": ModelOutput(\n",
    "            quantity=\"energy\",\n",
    "            unit=\"eV\",\n",
    "            per_atom=False,\n",
    "        ),\n",
    "    },\n",
    ")\n",
    "\n",
    "metatensor_model = MetatensorAtomisticModule(wrapper, capabilities)\n",
    "metatensor_model.export(\"ethanol-model-with-lj.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running some MD with our new model\n",
    "\n",
    "Let's see if these changes have made a difference to the stability of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ase.md\n",
    "import ase.units\n",
    "\n",
    "import chemiscope\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the same initial setup for the simulation\n",
    "\n",
    "atoms = frames[0]\n",
    "atoms.calc = MetatensorCalculator(\"ethanol-model-with-lj.pt\")\n",
    "\n",
    "integrator = ase.md.VelocityVerlet(atoms, timestep=1 * ase.units.fs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory = [atoms.copy()]\n",
    "\n",
    "for _ in range(200):\n",
    "    integrator.run(1)\n",
    "    trajectory.append(atoms.copy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemiscope.show(\n",
    "    trajectory, mode=\"structure\", settings={\"structure\": [{\"playbackDelay\": 50}]}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have fixed the issue of atoms getting way too close to one another! ðŸŽ‰\n",
    "\n",
    "We still have other problems, from the fairly low accuracy to the molecule now\n",
    "decomposing into individual atoms. There would be a handful of approaches to\n",
    "improve on this point (see at the end of notebook 2-ASE-md). If you have some\n",
    "time, feel free to go back to the model definition and training and improve on\n",
    "these points!\n",
    "\n",
    "For now, we'll see how we can take the exact same potential we just use in ASE\n",
    "and use it in a completely different simulation engine: LAMMPS."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtualenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
